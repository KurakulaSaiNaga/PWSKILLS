{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e56755c",
   "metadata": {},
   "source": [
    "# 1\n",
    "\n",
    "**Min-Max Scaling:**\n",
    "- Min-Max scaling, also known as normalization, is a data preprocessing technique that transforms the features to a specific range, typically between 0 and 1.\n",
    "- The formula for Min-Max scaling is: x_scaled = (x - x_min) / (x_max - x_min)\n",
    "- It ensures that all features have the same scale, making them comparable.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Example dataset\n",
    "data = [[1], [5], [10], [15], [20]]\n",
    "\n",
    "# Apply Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\", data)\n",
    "print(\"Scaled Data:\", scaled_data)\n",
    "```\n",
    "\n",
    "### 2\n",
    "\n",
    "**Unit Vector Technique:**\n",
    "- The Unit Vector technique, also known as Vector normalization or L2 normalization, scales the features to have a length of 1 (unit norm).\n",
    "- The formula for Unit Vector scaling is: \\( X_{\\text{scaled}} = \\frac{X}{\\|X\\|_2} \\)\n",
    "- It preserves the direction of the data while ensuring that all features are on the same scale.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Example dataset\n",
    "data = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "# Apply Unit Vector scaling\n",
    "scaler = Normalizer(norm='l2')\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\", data)\n",
    "print(\"Scaled Data:\", scaled_data)\n",
    "```\n",
    "\n",
    "### 3\n",
    "\n",
    "**PCA (Principal Component Analysis):**\n",
    "- PCA is a dimensionality reduction technique that transforms high-dimensional data into a lower-dimensional representation.\n",
    "- It identifies the principal components, which are linear combinations of the original features, capturing the most significant variance in the data.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "transformed_data = pca.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\", data)\n",
    "print(\"Transformed Data (2 Principal Components):\", transformed_data)\n",
    "```\n",
    "\n",
    "### 4\n",
    "\n",
    "**PCA and Feature Extraction:**\n",
    "- PCA can be used for feature extraction by transforming the original features into a set of linearly uncorrelated features (principal components).\n",
    "- The principal components represent the most important information in the data, allowing for dimensionality reduction.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'height': [170, 165, 180],\n",
    "    'weight': [65, 55, 80],\n",
    "    'age': [25, 30, 22],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply PCA for Feature Extraction\n",
    "pca = PCA(n_components=2)\n",
    "transformed_data = pca.fit_transform(df)\n",
    "\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"Transformed Data (2 Principal Components):\\n\", transformed_data)\n",
    "```\n",
    "\n",
    "### 5\n",
    "\n",
    "**Min-Max Scaling for Recommendation System:**\n",
    "- Apply Min-Max scaling to ensure that all features, such as price, rating, and delivery time, are on the same scale.\n",
    "- This ensures that no single feature dominates the recommendation process due to differences in scale.\n",
    "- Use the scaled features as input to the recommendation system.\n",
    "\n",
    "### 6\n",
    "\n",
    "**PCA for Dimensionality Reduction in Stock Price Prediction:**\n",
    "- Apply PCA to the dataset with features like company financial data and market trends.\n",
    "- Identify the principal components that capture the most significant variance in the data.\n",
    "- Select a suitable number of principal components to reduce the dimensionality.\n",
    "- Use the reduced set of principal components as input features for the stock price prediction model.\n",
    "\n",
    "### 7\n",
    "\n",
    "**Min-Max Scaling Example:**\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "data = np.array([1, 5, 10, 15, 20]).reshape(-1, 1)\n",
    "\n",
    "# Apply Min-Max scaling to transform values to the range of -1 to 1\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\", data.flatten())\n",
    "print(\"Scaled Data (-1 to 1):\", scaled_data.flatten())\n",
    "```\n",
    "\n",
    "### 8\n",
    "\n",
    "**PCA for Feature Extraction Example:**\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'height': [170, 165, 180],\n",
    "    'weight': [65, 55, 80],\n",
    "    'age': [25, 30, 22],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply PCA for Feature Extraction\n",
    "pca = PCA()\n",
    "transformed_data = pca.fit_transform(df)\n",
    "\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "```\n",
    "\n",
    "- Examine the explained variance ratio to decide how many principal components to retain.\n",
    "- You might choose a sufficient number of principal components that capture a high percentage (e.g., 95%) of the total variance.\n",
    "- The number of principal components retained depends on the desired balance between dimensionality reduction and information retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f18e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
