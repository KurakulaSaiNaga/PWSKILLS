{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6302d8",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb3b07",
   "metadata": {},
   "source": [
    "Ordinal encoding and label encoding are both techniques used in data preprocessing for machine learning, especially when dealing with categorical variables. However, they are used in slightly different contexts and have distinct characteristics:\n",
    "\n",
    "**1. Label Encoding:**\n",
    "   - Label encoding is primarily used for nominal data, where the categories have no inherent order or hierarchy. It assigns a unique integer label to each category in a categorical variable.\n",
    "   - The assignment of labels is arbitrary and does not carry any specific meaning in terms of the data's inherent structure.\n",
    "   - Label encoding is simple and efficient but may introduce unintended ordinal relationships if the model misinterprets the assigned labels as meaningful order.\n",
    "   - Example: Consider a \"Color\" variable with categories [\"Red\", \"Blue\", \"Green\"]. Label encoding might assign labels as {\"Red\": 0, \"Blue\": 1, \"Green\": 2}.\n",
    "\n",
    "**2. Ordinal Encoding:**\n",
    "   - Ordinal encoding is used for ordinal data, where the categories have a meaningful order or hierarchy. It assigns labels to categories in a way that reflects their natural order.\n",
    "   - The labels assigned in ordinal encoding have a specific meaning and can be used to indicate the relative order or ranking of the categories.\n",
    "   - Ordinal encoding is appropriate when there is a clear order among the categories, and you want the model to consider this order when making predictions.\n",
    "   - Example: Consider an \"Education Level\" variable with categories [\"High School\", \"Bachelor's\", \"Master's\", \"Ph.D.\"]. Ordinal encoding might assign labels as {\"High School\": 0, \"Bachelor's\": 1, \"Master's\": 2, \"Ph.D.\": 3}.\n",
    "\n",
    "When to Choose One Over the Other:\n",
    "- Choose Label Encoding:\n",
    "  - When dealing with nominal data where there is no meaningful order among the categories, and you want to represent the categories numerically without implying any ordinal relationship.\n",
    "  - Label encoding is suitable for features like \"Color,\" \"City,\" or \"Gender\" when you want to convert them into a numeric format.\n",
    "\n",
    "- Choose Ordinal Encoding:\n",
    "  - When working with ordinal data where there is a clear, predefined order or hierarchy among the categories, and you want to preserve and leverage this order.\n",
    "  - Ordinal encoding is appropriate for features like \"Education Level,\" \"Satisfaction Level,\" or \"Job Seniority\" where the order of categories matters and should be reflected in the encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee5427",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9b2e9",
   "metadata": {},
   "source": [
    "Target Guided Ordinal Encoding is a technique used to encode categorical variables when there is a strong relationship between the categorical feature and the target variable in a machine learning project. The goal is to capture the information in the categorical variable in a way that reflects how it influences the target variable. This can be particularly useful when the categorical feature has a significant impact on the target variable, and you want to preserve this relationship during the encoding process.\n",
    "\n",
    "Here's how Target Guided Ordinal Encoding typically works:\n",
    "\n",
    "1. Calculate the mean or some other summary statistic of the target variable for each category within the categorical feature. The summary statistic can be the mean, median, mode, or any other metric that makes sense for your specific problem.\n",
    "\n",
    "2. Sort the categories based on their associated summary statistics. Categories with higher summary statistics will be assigned higher ordinal values, reflecting their influence on the target variable. This ensures that categories more related to the target variable have higher encoding values.\n",
    "\n",
    "3. Assign the ordinal values to the original categorical feature based on the sorted order.\n",
    "\n",
    "Let's consider an example:\n",
    "\n",
    "Suppose you're working on a project to predict customer churn for a telecom company, and one of the categorical features is \"Plan Type,\" which includes categories like \"Basic,\" \"Silver,\" \"Gold,\" and \"Platinum.\" You have observed that there is a strong correlation between the plan type and the likelihood of customer churn. Customers with higher-tier plans (e.g., \"Platinum\") tend to have a lower churn rate compared to those with lower-tier plans (e.g., \"Basic\").\n",
    "\n",
    "To use Target Guided Ordinal Encoding in this scenario:\n",
    "\n",
    "1. Calculate the mean churn rate for each plan type:\n",
    "   - Basic: 0.35 (35% churn rate)\n",
    "   - Silver: 0.25 (25% churn rate)\n",
    "   - Gold: 0.15 (15% churn rate)\n",
    "   - Platinum: 0.10 (10% churn rate)\n",
    "\n",
    "2. Sort the plan types based on their associated churn rates (in ascending order):\n",
    "   - Platinum\n",
    "   - Gold\n",
    "   - Silver\n",
    "   - Basic\n",
    "\n",
    "3. Assign ordinal values:\n",
    "   - Platinum: 0\n",
    "   - Gold: 1\n",
    "   - Silver: 2\n",
    "   - Basic: 3\n",
    "\n",
    "Now, the \"Plan Type\" feature has been encoded in a way that reflects the relationship between plan types and churn rates, with higher-tier plans receiving lower ordinal values.\n",
    "\n",
    "This encoding can help the machine learning model better understand and utilize the relationship between the \"Plan Type\" feature and the target variable (churn), potentially leading to improved predictive accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b7105",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250ccf3",
   "metadata": {},
   "source": [
    "Covariance is a statistical measure that quantifies the degree to which two random variables change together. It indicates whether there is a linear relationship between the variables and whether they tend to increase or decrease together. In other words, covariance measures the joint variability of two random variables.\n",
    "\n",
    "Key points about covariance:\n",
    "\n",
    "1. Sign of Covariance:\n",
    "   - A positive covariance indicates that when one variable increases, the other variable tends to increase as well.\n",
    "   - A negative covariance indicates that when one variable increases, the other variable tends to decrease.\n",
    "\n",
    "2. Magnitude of Covariance:\n",
    "   - The magnitude of covariance indicates the strength of the relationship between the two variables. A larger absolute value of covariance suggests a stronger relationship.\n",
    "\n",
    "Covariance is essential in statistical analysis for several reasons:\n",
    "\n",
    "1. Relationship Assessment: Covariance helps in understanding how two variables are related to each other. It provides insights into whether changes in one variable are associated with changes in another variable.\n",
    "\n",
    "2. Portfolio Management: In finance, covariance is used to assess the risk and diversification benefits of combining multiple assets in an investment portfolio. Low or negative covariances between assets can reduce overall portfolio risk.\n",
    "\n",
    "3. Multivariate Analysis: In multivariate statistics, covariance is used to understand how multiple variables interact and co-vary. For example, it's crucial in principal component analysis (PCA) and factor analysis.\n",
    "\n",
    "Covariance is calculated using the following formula:\n",
    "\n",
    "\\[ \\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) \\]\n",
    "\n",
    "Where:\n",
    "\n",
    "\n",
    "- Cov(X,Y) is the covariance between random variables X and Y.\n",
    "- n is the number of data points.\n",
    "- xi and yi are the individual data points in the datasets X and Y.\n",
    "- xi and yi are the individual data points in the datasets X and Y.\n",
    "\n",
    "The formula calculates the average of the products of the differences between each data point and the mean of their respective variables. This measures how each data point's deviation from its mean is related to the deviation of the other data points from their means. The division by \\(n-1\\) (instead of \\(n\\)) is used to make the sample covariance an unbiased estimator of the population covariance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c72b73",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c5bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Data:\n",
      "Color: [2 1 0 2 1]\n",
      "Size: [2 1 0 1 2]\n",
      "Material: [2 0 1 2 0]\n",
      "\n",
      "Label Encoders:\n",
      "Color: ['blue' 'green' 'red']\n",
      "Size: ['large' 'medium' 'small']\n",
      "Material: ['metal' 'plastic' 'wood']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = {\n",
    "    \"Color\": [\"red\", \"green\", \"blue\", \"red\", \"green\"],\n",
    "    \"Size\": [\"small\", \"medium\", \"large\", \"medium\", \"small\"],\n",
    "    \"Material\": [\"wood\", \"metal\", \"plastic\", \"wood\", \"metal\"]\n",
    "}\n",
    "\n",
    "label_encoders = {}\n",
    "encoded_data = {}\n",
    "\n",
    "for column in data:\n",
    "    le = LabelEncoder()\n",
    "    encoded_data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "print(\"Encoded Data:\")\n",
    "for column in encoded_data:\n",
    "    print(f\"{column}: {encoded_data[column]}\")\n",
    "\n",
    "print(\"\\nLabel Encoders:\")\n",
    "for column in label_encoders:\n",
    "    print(f\"{column}: {label_encoders[column].classes_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b1d3e",
   "metadata": {},
   "source": [
    "- We start by defining a sample dataset with three categorical variables: \"Color,\" \"Size,\" and \"Material.\"\n",
    "\n",
    "- We create a LabelEncoder object for each categorical variable and use the fit_transform method to encode the categorical values into numerical labels.\n",
    "\n",
    "- The encoded data is stored in the encoded_data dictionary, where the keys are the column names (\"Color,\" \"Size,\" \"Material\"), and the values are the encoded labels.\n",
    "\n",
    "- We also store the LabelEncoder objects in the label_encoders dictionary, which can be used later to decode the labels back to the original categorical values.\n",
    "\n",
    "- Finally, we print the encoded data and the label encoders. The label encoders show the mapping between the original categorical values and their corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e383968",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9f8b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      "[[4.930e+01 7.275e+04 1.210e+01]\n",
      " [7.275e+04 1.325e+08 2.300e+04]\n",
      " [1.210e+01 2.300e+04 5.200e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "age = [35, 42, 28, 45, 32]\n",
    "income = [50000, 60000, 45000, 75000, 55000]\n",
    "education_level = [12, 16, 14, 18, 14]\n",
    "\n",
    "data_matrix = np.array([age, income, education_level])\n",
    "\n",
    "covariance_matrix = np.cov(data_matrix)\n",
    "\n",
    "print(\"Covariance Matrix:\")\n",
    "print(covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc6a14",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ab8b9",
   "metadata": {},
   "source": [
    "When deciding on the encoding method for categorical variables in a machine learning project, it's essential to consider the nature of each variable and how they are best represented for your specific modeling task. Here's how you might choose the encoding method for each of the mentioned categorical variables:\n",
    "\n",
    "1. \"Gender\" (Binary Categorical Variable - Male/Female):\n",
    "   - Encoding Method: Binary Encoding or One-Hot Encoding\n",
    "   - Explanation: Since \"Gender\" is binary (Male or Female), you can use binary encoding (0 for Male, 1 for Female) or one-hot encoding, which creates two binary columns (e.g., \"IsMale\" and \"IsFemale\") to represent the categories. The choice between binary and one-hot encoding depends on your model and whether you want to explicitly represent both genders as separate features or just a single binary feature.\n",
    "\n",
    "2. \"Education Level\" (Ordinal Categorical Variable - High School/Bachelor's/Master's/PhD):\n",
    "   - Encoding Method: Ordinal Encoding\n",
    "   - Explanation: \"Education Level\" is ordinal, meaning there is a clear order and hierarchy among the categories. You should use ordinal encoding, which assigns labels in a way that reflects the natural order (e.g., High School: 0, Bachelor's: 1, Master's: 2, PhD: 3). This preserves the ordinal relationships between education levels and allows the model to consider this order during predictions.\n",
    "\n",
    "3. \"Employment Status\" (Nominal Categorical Variable - Unemployed/Part-Time/Full-Time):\n",
    "   - Encoding Method: One-Hot Encoding\n",
    "   - Explanation: \"Employment Status\" is nominal, where there is no inherent order among the categories. One-hot encoding is suitable for nominal variables, as it creates binary columns for each category, effectively representing each category as a distinct feature (e.g., \"IsUnemployed,\" \"IsPartTime,\" \"IsFullTime\"). This ensures that there is no implied ordinal relationship between the categories, and the model can treat them as separate and equal factors.\n",
    "\n",
    "In summary, the choice of encoding method depends on the nature of the categorical variable:\n",
    "\n",
    "- Binary variables like \"Gender\" can use binary encoding or one-hot encoding, depending on how you want to represent them.\n",
    "- Ordinal variables like \"Education Level\" should use ordinal encoding to maintain the meaningful order.\n",
    "- Nominal variables like \"Employment Status\" are best encoded using one-hot encoding to treat the categories as independent factors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd1058",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7be95cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Covariance Matrix:\n",
      "             Temperature  Humidity\n",
      "Temperature         10.2     -18.9\n",
      "Humidity           -18.9      35.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'Temperature': [25, 22, 20, 28, 26],\n",
    "    'Humidity': [60, 65, 70, 55, 58],\n",
    "    'Weather Condition': ['Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Cloudy'],\n",
    "    'Wind Direction': ['North', 'South', 'East', 'West', 'North']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "cov_matrix = df[numeric_columns].cov()\n",
    "print('\\nCovariance Matrix:')\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e51e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
