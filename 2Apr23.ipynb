{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ec9b00-0965-4b76-a908-82148e5bcdc9",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "**Purpose of Grid Search CV:**\n",
    "Grid Search Cross-Validation (CV) is used to systematically work through multiple combinations of hyperparameter values, cross-validate each combination, and determine the best model parameters that yield the highest performance.\n",
    "\n",
    "**How It Works:**\n",
    "1. **Specify Hyperparameter Grid:** Define a set of hyperparameters and their possible values to search through.\n",
    "2. **Exhaustive Search:** For each combination of hyperparameters:\n",
    "   - Split the training data into k-folds.\n",
    "   - Train the model on  k-1  folds and validate it on the remaining fold.\n",
    "   - Repeat for all folds and calculate the average performance metric (e.g., accuracy, F1-score).\n",
    "3. **Select Best Parameters:** Choose the hyperparameter combination with the best average performance across the k-folds.\n",
    "4. **Refit Model:** Train the final model on the entire training dataset using the best hyperparameters.\n",
    "\n",
    "## 2\n",
    "**Grid Search CV:**\n",
    "- **Search Method:** Exhaustively searches all possible combinations of hyperparameters.\n",
    "- **Pros:** Guarantees finding the optimal combination within the specified grid.\n",
    "- **Cons:** Computationally expensive and time-consuming, especially with a large number of hyperparameters and values.\n",
    "\n",
    "**Randomized Search CV:**\n",
    "- **Search Method:** Samples a fixed number of hyperparameter combinations randomly from the specified grid.\n",
    "- **Pros:** Faster and more efficient than grid search, especially when dealing with a large hyperparameter space.\n",
    "- **Cons:** Does not guarantee finding the absolute best combination but usually finds a good enough solution.\n",
    "\n",
    "**When to Choose:**\n",
    "- **Grid Search CV:** When the hyperparameter space is small or when computational resources and time are not a constraint.\n",
    "- **Randomized Search CV:** When dealing with a large hyperparameter space or limited computational resources and time.\n",
    "\n",
    "## 3\n",
    "\n",
    "**Data Leakage:**\n",
    "Data leakage occurs when information from outside the training dataset is used to create the model, resulting in overly optimistic performance estimates and poor generalization to new data.\n",
    "\n",
    "**Why It’s a Problem:**\n",
    "- It leads to models that perform well on the training data but fail to generalize to unseen data.\n",
    "- It can cause incorrect conclusions about the model’s performance and effectiveness.\n",
    "\n",
    "**Example:**\n",
    "Consider predicting customer churn using features like customer tenure and whether the customer churned last month. If the training data includes this information from the future (i.e., post-churn), the model may learn to predict churn based on future information, leading to misleadingly high performance.\n",
    "\n",
    "## 4\n",
    "\n",
    "**Preventing Data Leakage:**\n",
    "1. **Separate Data Properly:** Ensure that the training, validation, and test datasets are correctly separated and no data is shared between them.\n",
    "2. **Feature Engineering:** Perform feature engineering (e.g., scaling, encoding) within cross-validation to prevent information from the validation set leaking into the training process.\n",
    "3. **Temporal Ordering:** For time-series data, maintain temporal order by training on past data and testing on future data.\n",
    "4. **Careful Feature Selection:** Avoid using features that won’t be available at prediction time or that contain information from the future.\n",
    "\n",
    "## 5\n",
    "\n",
    "**Confusion Matrix:**\n",
    "A confusion matrix is a table that summarizes the performance of a classification model by comparing the actual labels with the predicted labels. It consists of four components:\n",
    "- **True Positives (TP):** Correctly predicted positive cases.\n",
    "- **True Negatives (TN):** Correctly predicted negative cases.\n",
    "- **False Positives (FP):** Incorrectly predicted positive cases.\n",
    "- **False Negatives (FN):** Incorrectly predicted negative cases.\n",
    "\n",
    "**Performance Insights:**\n",
    "- Provides a detailed breakdown of correct and incorrect classifications.\n",
    "- Helps identify types of errors the model makes (e.g., false positives vs. false negatives).\n",
    "\n",
    "## 6\n",
    "\n",
    "**Precision:**\n",
    "- **Definition:** The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "- **Formula:** *Precision* = TP/{TP + FP}\n",
    "- **Focus:** Measures the accuracy of positive predictions.\n",
    "\n",
    "**Recall (Sensitivity):**\n",
    "- **Definition:** The ratio of correctly predicted positive observations to the actual positives.\n",
    "- **Formula:** *Recall* = TP/{TP + FN}\n",
    "- **Focus:** Measures the model’s ability to capture all positive cases.\n",
    "\n",
    "## 7\n",
    "\n",
    "**Interpreting Errors:**\n",
    "- **False Positives (FP):** Instances where the model incorrectly predicts the positive class. High FP indicates the model is too lenient in classifying positives.\n",
    "- **False Negatives (FN):** Instances where the model incorrectly predicts the negative class. High FN indicates the model is too strict in classifying positives.\n",
    "- By analyzing the counts of FP and FN, you can determine if your model tends to favor one class over the other and adjust accordingly (e.g., adjusting the decision threshold).\n",
    "\n",
    "## 8\n",
    "\n",
    "**Common Metrics:**\n",
    "1. **Accuracy:**\n",
    "   - **Formula:** *Accuracy* = {TP + TN}/{TP + TN + FP + FN}\n",
    "   - Measures the overall correctness of the model.\n",
    "\n",
    "2. **Precision:**\n",
    "   - **Formula:** *Precision* = TP/{TP + FP}\n",
    "   - Measures the accuracy of positive predictions.\n",
    "\n",
    "3. **Recall (Sensitivity):**\n",
    "   - **Formula:** *Recall* = TP/{TP + FN}\n",
    "   - Measures the ability to capture all positive cases.\n",
    "\n",
    "4. **F1-Score:**\n",
    "   - **Formula:**  F1 = 2 . {Precision.Recall}/{Precision + Recall}\n",
    "   - Harmonic mean of precision and recall, balancing both metrics.\n",
    "\n",
    "5. **Specificity:**\n",
    "   - **Formula:** *Specificity* = TN/{TN + FP}\n",
    "   - Measures the ability to capture all negative cases.\n",
    "\n",
    "## 9\n",
    "\n",
    "**Relationship:**\n",
    "- **Accuracy:** Measures the proportion of correct predictions (both true positives and true negatives) among all predictions.\n",
    "- **Calculation:** Directly derived from the confusion matrix values:\n",
    "   *Accuracy* = {TP + TN}/{TP + TN + FP + FN} \n",
    "- **Limitations:** Accuracy can be misleading in imbalanced datasets where one class dominates.\n",
    "\n",
    "## 10\n",
    "\n",
    "**Identifying Biases and Limitations:**\n",
    "- **Class Imbalance:** High number of false negatives or false positives might indicate a bias towards the majority class.\n",
    "- **Error Patterns:** Consistent errors in certain classes can indicate areas where the model is underperforming.\n",
    "- **Threshold Adjustment:** Use precision-recall trade-offs to adjust the decision threshold based on the type of errors you want to minimize (e.g., reducing false negatives in medical diagnoses).\n",
    "- **Performance Across Classes:** Analyze metrics like precision, recall, and F1-score for each class to ensure balanced performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a827bf-ea0d-413e-b061-d2d5dcda630a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
